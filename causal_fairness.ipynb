{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness anaysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device to CUDA if available, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET BASELINE FAIRNESS ANALYSIS ===\n",
      "Total samples: 12611\n",
      "\n",
      "COVID Distribution:\n",
      "  COVID Positive: 0.453 (5718 cases)\n",
      "  COVID Negative: 0.547 (6893 cases)\n",
      "\n",
      "Gender Distribution:\n",
      "  Gender 1: 0.620 (7818 cases)\n",
      "  Gender 0: 0.380 (4793 cases)\n",
      "\n",
      "Age Distribution:\n",
      "  Mean age (normalized): 0.000\n",
      "  Std age (normalized): 1.000\n",
      "\n",
      "Country Distribution:\n",
      "  Country 1: 0.515 (6493 cases)\n",
      "  Country 3: 0.465 (5865 cases)\n",
      "  Country 2: 0.008 (103 cases)\n",
      "  Country 0: 0.006 (72 cases)\n",
      "  Country 4: 0.003 (44 cases)\n",
      "  Country 5: 0.003 (34 cases)\n",
      "\n",
      "Institution Distribution:\n",
      "  Institution 2: 0.465 (5865 cases)\n",
      "  Institution 0: 0.363 (4575 cases)\n",
      "  Institution 3: 0.136 (1719 cases)\n",
      "  Institution 7: 0.016 (199 cases)\n",
      "  Institution 4: 0.008 (103 cases)\n",
      "  Institution 5: 0.006 (72 cases)\n",
      "  Institution 6: 0.003 (44 cases)\n",
      "  Institution 1: 0.003 (34 cases)\n",
      "\n",
      "============================================================\n",
      "INHERENT DATASET BIAS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. AGE GROUP BIAS IN GROUND TRUTH:\n",
      "            Group  Size  COVID_Rate  Percentage\n",
      "age_binned=Middle  3986    0.534621   31.607327\n",
      " age_binned=Older  4055    0.404686   32.154468\n",
      " age_binned=Young  4570    0.425821   36.238205\n",
      "Ground Truth Age DPD: 0.1299\n",
      "\n",
      "2. GENDER GROUP BIAS IN GROUND TRUTH:\n",
      "           Group  Size  COVID_Rate  Percentage\n",
      "Gender_encoded=0  4793    0.447319   38.006502\n",
      "Gender_encoded=1  7818    0.457150   61.993498\n",
      "Ground Truth Gender DPD: 0.0098\n",
      "\n",
      "3. COUNTRY GROUP BIAS IN GROUND TRUTH:\n",
      "            Group  Size  COVID_Rate  Percentage\n",
      "Country_encoded=0    72    1.000000    0.570930\n",
      "Country_encoded=1  6493    0.720776   51.486797\n",
      "Country_encoded=2   103    1.000000    0.816747\n",
      "Country_encoded=3  5865    0.133845   46.507018\n",
      "Country_encoded=4    44    1.000000    0.348902\n",
      "Country_encoded=5    34    1.000000    0.269606\n",
      "Ground Truth Country DPD: 0.8662\n",
      "\n",
      "4. INSTITUTION GROUP BIAS IN GROUND TRUTH:\n",
      "                Group  Size  COVID_Rate  Percentage\n",
      "Institution_encoded=0  4575    0.833880   36.277853\n",
      "Institution_encoded=1    34    1.000000    0.269606\n",
      "Institution_encoded=2  5865    0.133845   46.507018\n",
      "Institution_encoded=3  1719    0.387435   13.630957\n",
      "Institution_encoded=4   103    1.000000    0.816747\n",
      "Institution_encoded=5    72    1.000000    0.570930\n",
      "Institution_encoded=6    44    1.000000    0.348902\n",
      "Institution_encoded=7   199    1.000000    1.577987\n",
      "Ground Truth Institution DPD: 0.8662\n"
     ]
    }
   ],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_csv(\"/home/hailemicaelyimer/fairness/Data_working_now/cleaned_metadata.csv\")\n",
    "\n",
    "print(\"=== DATASET BASELINE FAIRNESS ANALYSIS ===\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "# Basic demographics\n",
    "print(f\"\\nCOVID Distribution:\")\n",
    "covid_dist = df['y_true'].value_counts(normalize=True)\n",
    "print(f\"  COVID Positive: {covid_dist[1]:.3f} ({covid_dist[1]*len(df):.0f} cases)\")\n",
    "print(f\"  COVID Negative: {covid_dist[0]:.3f} ({covid_dist[0]*len(df):.0f} cases)\")\n",
    "\n",
    "print(f\"\\nGender Distribution:\")\n",
    "gender_dist = df['Gender_encoded'].value_counts(normalize=True)\n",
    "for gender, prop in gender_dist.items():\n",
    "    print(f\"  Gender {gender}: {prop:.3f} ({prop*len(df):.0f} cases)\")\n",
    "\n",
    "print(f\"\\nAge Distribution:\")\n",
    "print(f\"  Mean age (normalized): {df['Age_normalized'].mean():.3f}\")\n",
    "print(f\"  Std age (normalized): {df['Age_normalized'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nCountry Distribution:\")\n",
    "country_dist = df['Country_encoded'].value_counts(normalize=True)\n",
    "for country, prop in country_dist.items():\n",
    "    print(f\"  Country {country}: {prop:.3f} ({prop*len(df):.0f} cases)\")\n",
    "\n",
    "print(f\"\\nInstitution Distribution:\")\n",
    "inst_dist = df['Institution_encoded'].value_counts(normalize=True)\n",
    "for inst, prop in inst_dist.items():\n",
    "    print(f\"  Institution {inst}: {prop:.3f} ({prop*len(df):.0f} cases)\")\n",
    "\n",
    "# Now analyze inherent bias in the dataset (ground truth labels)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INHERENT DATASET BIAS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def analyze_group_bias(df, group_col, label_col='y_true'):\n",
    "    \"\"\"Analyze bias in ground truth labels by demographic groups\"\"\"\n",
    "    group_stats = []\n",
    "    \n",
    "    for group_val in sorted(df[group_col].unique()):\n",
    "        group_df = df[df[group_col] == group_val]\n",
    "        covid_rate = group_df[label_col].mean()\n",
    "        group_size = len(group_df)\n",
    "        \n",
    "        group_stats.append({\n",
    "            'Group': f\"{group_col}={group_val}\",\n",
    "            'Size': group_size,\n",
    "            'COVID_Rate': covid_rate,\n",
    "            'Percentage': group_size / len(df) * 100\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(group_stats)\n",
    "\n",
    "# Analyze inherent bias in ground truth labels\n",
    "print(\"\\n1. AGE GROUP BIAS IN GROUND TRUTH:\")\n",
    "# Create age bins for analysis\n",
    "df['age_binned'] = pd.qcut(df['Age_normalized'], q=3, labels=['Young', 'Middle', 'Older'], duplicates='drop')\n",
    "age_bias = analyze_group_bias(df, 'age_binned')\n",
    "print(age_bias.to_string(index=False))\n",
    "\n",
    "age_covid_rates = age_bias['COVID_Rate'].values\n",
    "age_dpd_ground_truth = age_covid_rates.max() - age_covid_rates.min()\n",
    "print(f\"Ground Truth Age DPD: {age_dpd_ground_truth:.4f}\")\n",
    "\n",
    "print(\"\\n2. GENDER GROUP BIAS IN GROUND TRUTH:\")\n",
    "gender_bias = analyze_group_bias(df, 'Gender_encoded')\n",
    "print(gender_bias.to_string(index=False))\n",
    "\n",
    "gender_covid_rates = gender_bias['COVID_Rate'].values\n",
    "gender_dpd_ground_truth = gender_covid_rates.max() - gender_covid_rates.min()\n",
    "print(f\"Ground Truth Gender DPD: {gender_dpd_ground_truth:.4f}\")\n",
    "\n",
    "print(\"\\n3. COUNTRY GROUP BIAS IN GROUND TRUTH:\")\n",
    "country_bias = analyze_group_bias(df, 'Country_encoded')\n",
    "print(country_bias.to_string(index=False))\n",
    "\n",
    "country_covid_rates = country_bias['COVID_Rate'].values\n",
    "country_dpd_ground_truth = country_covid_rates.max() - country_covid_rates.min()\n",
    "print(f\"Ground Truth Country DPD: {country_dpd_ground_truth:.4f}\")\n",
    "\n",
    "print(\"\\n4. INSTITUTION GROUP BIAS IN GROUND TRUTH:\")\n",
    "inst_bias = analyze_group_bias(df, 'Institution_encoded')\n",
    "print(inst_bias.to_string(index=False))\n",
    "\n",
    "inst_covid_rates = inst_bias['COVID_Rate'].values\n",
    "inst_dpd_ground_truth = inst_covid_rates.max() - inst_covid_rates.min()\n",
    "print(f\"Ground Truth Institution DPD: {inst_dpd_ground_truth:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness mitigation with causal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded CSV with 12611 entries\n",
      "After removing duplicates: 12611 entries\n",
      "After cleaning: 12611 entries\n",
      "Epoch 1/50\n",
      "Train Loss: 1.7709\n",
      "Val Loss: 1.3453, Accuracy: 0.8103, Precision: 0.7570, Recall: 0.8566, F1: 0.8037\n",
      "Saved best model with Val F1: 0.8037\n",
      "Epoch 2/50\n",
      "Train Loss: 1.3831\n",
      "Val Loss: 2.5485, Accuracy: 0.7463, Precision: 0.9163, Recall: 0.4848, F1: 0.6341\n",
      "Epoch 3/50\n",
      "Train Loss: 1.3889\n",
      "Val Loss: 1.9500, Accuracy: 0.5877, Precision: 0.7868, Recall: 0.1247, F1: 0.2153\n",
      "Epoch 4/50\n",
      "Train Loss: 1.3471\n",
      "Val Loss: 1.4856, Accuracy: 0.8134, Precision: 0.7595, Recall: 0.8613, F1: 0.8072\n",
      "Saved best model with Val F1: 0.8072\n",
      "Epoch 5/50\n",
      "Train Loss: 1.2844\n",
      "Val Loss: 1.4340, Accuracy: 0.7146, Precision: 1.0000, Recall: 0.3706, F1: 0.5408\n",
      "Epoch 6/50\n",
      "Train Loss: 1.2369\n",
      "Val Loss: 1.8278, Accuracy: 0.8927, Precision: 0.9304, Recall: 0.8252, F1: 0.8746\n",
      "Saved best model with Val F1: 0.8746\n",
      "Epoch 7/50\n",
      "Train Loss: 1.2336\n",
      "Val Loss: 1.1829, Accuracy: 0.8895, Precision: 0.9577, Recall: 0.7914, F1: 0.8666\n",
      "Epoch 8/50\n",
      "Train Loss: 1.2848\n",
      "Val Loss: 1.2305, Accuracy: 0.8325, Precision: 0.8063, Recall: 0.8298, F1: 0.8179\n",
      "Epoch 9/50\n",
      "Train Loss: 1.2062\n",
      "Val Loss: 1.1909, Accuracy: 0.8821, Precision: 0.9922, Recall: 0.7459, F1: 0.8516\n",
      "Epoch 10/50\n",
      "Train Loss: 1.1947\n",
      "Val Loss: 1.2466, Accuracy: 0.8451, Precision: 0.8087, Recall: 0.8625, F1: 0.8347\n",
      "Epoch 11/50\n",
      "Train Loss: 1.1669\n",
      "Val Loss: 1.7605, Accuracy: 0.7981, Precision: 0.7297, Recall: 0.8811, F1: 0.7983\n",
      "Epoch 12/50\n",
      "Train Loss: 1.1566\n",
      "Val Loss: 1.0719, Accuracy: 0.9170, Precision: 0.9692, Recall: 0.8438, F1: 0.9022\n",
      "Saved best model with Val F1: 0.9022\n",
      "Epoch 13/50\n",
      "Train Loss: 1.1259\n",
      "Val Loss: 1.2310, Accuracy: 0.8562, Precision: 0.8256, Recall: 0.8660, F1: 0.8453\n",
      "Epoch 14/50\n",
      "Train Loss: 1.1017\n",
      "Val Loss: 1.0923, Accuracy: 0.8996, Precision: 0.9613, Recall: 0.8112, F1: 0.8799\n",
      "Epoch 15/50\n",
      "Train Loss: 1.0659\n",
      "Val Loss: 1.3518, Accuracy: 0.7854, Precision: 0.9913, Recall: 0.5315, F1: 0.6920\n",
      "Epoch 16/50\n",
      "Train Loss: 1.0549\n",
      "Val Loss: 1.1324, Accuracy: 0.8832, Precision: 0.8778, Recall: 0.8625, F1: 0.8701\n",
      "Epoch 17/50\n",
      "Train Loss: 1.0131\n",
      "Val Loss: 1.0249, Accuracy: 0.8853, Precision: 0.9863, Recall: 0.7576, F1: 0.8570\n",
      "Epoch 18/50\n",
      "Train Loss: 0.9301\n",
      "Val Loss: 0.8751, Accuracy: 0.9244, Precision: 0.9904, Recall: 0.8415, F1: 0.9099\n",
      "Saved best model with Val F1: 0.9099\n",
      "Epoch 19/50\n",
      "Train Loss: 0.8732\n",
      "Val Loss: 0.8964, Accuracy: 0.8943, Precision: 0.9985, Recall: 0.7681, F1: 0.8682\n",
      "Epoch 20/50\n",
      "Train Loss: 0.8563\n",
      "Val Loss: 1.1262, Accuracy: 0.9154, Precision: 0.9616, Recall: 0.8473, F1: 0.9009\n",
      "Epoch 21/50\n",
      "Train Loss: 0.8079\n",
      "Val Loss: 0.7400, Accuracy: 0.9355, Precision: 0.9682, Recall: 0.8869, F1: 0.9258\n",
      "Saved best model with Val F1: 0.9258\n",
      "Epoch 22/50\n",
      "Train Loss: 0.7788\n",
      "Val Loss: 0.7865, Accuracy: 0.9234, Precision: 0.9986, Recall: 0.8322, F1: 0.9078\n",
      "Epoch 23/50\n",
      "Train Loss: 0.7370\n",
      "Val Loss: 0.7854, Accuracy: 0.8959, Precision: 0.8803, Recall: 0.8916, F1: 0.8859\n",
      "Epoch 24/50\n",
      "Train Loss: 0.6817\n",
      "Val Loss: 0.6911, Accuracy: 0.9276, Precision: 0.9359, Recall: 0.9021, F1: 0.9187\n",
      "Epoch 25/50\n",
      "Train Loss: 0.6774\n",
      "Val Loss: 0.6718, Accuracy: 0.9297, Precision: 0.9537, Recall: 0.8881, F1: 0.9197\n",
      "Epoch 26/50\n",
      "Train Loss: 0.6285\n",
      "Val Loss: 6.7573, Accuracy: 0.7970, Precision: 0.7040, Recall: 0.9534, F1: 0.8099\n",
      "Epoch 27/50\n",
      "Train Loss: 0.6253\n",
      "Val Loss: 0.6617, Accuracy: 0.9461, Precision: 0.9922, Recall: 0.8881, F1: 0.9373\n",
      "Saved best model with Val F1: 0.9373\n",
      "Epoch 28/50\n",
      "Train Loss: 0.5968\n",
      "Val Loss: 0.6189, Accuracy: 0.9641, Precision: 0.9841, Recall: 0.9359, F1: 0.9594\n",
      "Saved best model with Val F1: 0.9594\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "base_dir = \"/home/hailemicaelyimer/fairness/Data_working_now/curated_data/curated_data\"\n",
    "covid_dir = os.path.join(base_dir, \"2COVID\")\n",
    "non_covid_dir = os.path.join(base_dir, \"1NonCOVID\")\n",
    "csv_path = \"/home/hailemicaelyimer/fairness/Data_working_now/cleaned_metadata.csv\"\n",
    "output_dir = \"/home/hailemicaelyimer/fairness/resnettt50\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded CSV with {len(df)} entries\")\n",
    "\n",
    "# Concept columns (including task as last)\n",
    "concept_cols = ['Age_normalized', 'Gender_encoded', 'Country_encoded', 'Institution_encoded', 'y_true']\n",
    "\n",
    "# Remove duplicates based on patient/image context (e.g., same File name)\n",
    "df = df.drop_duplicates(subset=['File name'])\n",
    "print(f\"After removing duplicates: {len(df)} entries\")\n",
    "\n",
    "# Normalize categorical encoded to 0-1 using max values from the dataset\n",
    "max_country = df['Country_encoded'].max()\n",
    "max_institution = df['Institution_encoded'].max()\n",
    "df['Country_encoded'] /= max_country\n",
    "df['Institution_encoded'] /= max_institution\n",
    "\n",
    "# Clean data: Drop NaNs and clip to [0,1] to prevent loss errors\n",
    "df = df.dropna(subset=concept_cols)\n",
    "df[concept_cols] = df[concept_cols].clip(0, 1)  # Clip all to [0,1], including Age_normalized\n",
    "print(f\"After cleaning: {len(df)} entries\")\n",
    "\n",
    "# Custom Dataset\n",
    "class C2BMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.concepts = torch.tensor(df[concept_cols].values, dtype=torch.float32)  # All concepts + task\n",
    "        self.filenames = df['File name'].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.filenames[idx]\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        covid_path = os.path.join(covid_dir, f\"{base_name}.png\")\n",
    "        non_covid_path = os.path.join(non_covid_dir, f\"{base_name}.png\")\n",
    "        \n",
    "        # Check COVID directory first\n",
    "        if os.path.exists(covid_dir) and os.path.isfile(covid_path):\n",
    "            img_path = covid_path\n",
    "        # Then check Non-COVID directory\n",
    "        elif os.path.exists(non_covid_dir) and os.path.isfile(non_covid_path):\n",
    "            img_path = non_covid_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Image not found for {file_name} in either COVID or Non-COVID directories\")\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        concepts = self.concepts[idx]\n",
    "        return image, concepts, img_path\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Split data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, stratify=df['y_true'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, stratify=temp_df['y_true'])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = C2BMDataset(train_df, transform=transform)\n",
    "val_dataset = C2BMDataset(val_df, transform=transform)\n",
    "test_dataset = C2BMDataset(test_df, transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# C2BM Model with Dropout for Regularization using ResNet-50\n",
    "class C2BMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C2BMModel, self).__init__()\n",
    "        # Use ResNet-50 instead of EfficientNet-B0\n",
    "        self.image_encoder = models.resnet50(weights=None)  # Use ResNet-50, no pretrained weights\n",
    "        self.image_encoder.fc = nn.Identity()  # Remove final fully connected layer to get 2048 features\n",
    "        \n",
    "        self.num_concepts = 5  # Age(0), Gender(1), Country(2), Institution(3), COVID(4)\n",
    "        self.u_dim = 64\n",
    "        self.u_encoder = nn.Linear(2048, self.num_concepts * self.u_dim)  # Adjusted for ResNet-50 output (2048 features)\n",
    "        \n",
    "        # Causal graph parents\n",
    "        self.parents = {\n",
    "            0: [],  # Age\n",
    "            1: [],  # Gender\n",
    "            2: [],  # Country\n",
    "            3: [2],  # Institution <- Country\n",
    "            4: [0, 1, 3]  # COVID <- Age, Gender, Institution\n",
    "        }\n",
    "        \n",
    "        # Meta-models for each concept with dropout\n",
    "        self.meta_models = nn.ModuleList()\n",
    "        for i in range(self.num_concepts):\n",
    "            num_pa = len(self.parents[i])\n",
    "            if num_pa == 0:  # Sources: MLP to logit\n",
    "                self.meta_models.append(nn.Sequential(\n",
    "                    nn.Linear(self.u_dim, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),  # Add dropout for regularization\n",
    "                    nn.Linear(32, 1)\n",
    "                ))\n",
    "            else:  # Non-sources: MLP to weights (theta) for parents\n",
    "                self.meta_models.append(nn.Sequential(\n",
    "                    nn.Linear(self.u_dim, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),  # Add dropout for regularization\n",
    "                    nn.Linear(32, num_pa)\n",
    "                ))\n",
    "        # Initialize weights\n",
    "        for module in self.meta_models:\n",
    "            for layer in module:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                    nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, image, intervention=None):\n",
    "        img_feat = self.image_encoder(image)\n",
    "        u_flat = self.u_encoder(img_feat)\n",
    "        U = u_flat.view(-1, self.num_concepts, self.u_dim)\n",
    "        \n",
    "        V = [None] * self.num_concepts\n",
    "        for i in range(self.num_concepts):  # Topological order\n",
    "            u_i = U[:, i, :]\n",
    "            pa = self.parents[i]\n",
    "            if len(pa) == 0:\n",
    "                logit = self.meta_models[i](u_i)\n",
    "            else:\n",
    "                theta = self.meta_models[i](u_i)\n",
    "                pa_v = torch.stack([V[j] for j in pa], dim=1)\n",
    "                logit = torch.sum(theta.unsqueeze(-1) * pa_v, dim=1)\n",
    "            \n",
    "            v_i = torch.sigmoid(logit)\n",
    "            \n",
    "            if intervention and i in intervention:\n",
    "                v_i = torch.full_like(v_i, intervention[i])\n",
    "            \n",
    "            V[i] = v_i\n",
    "        \n",
    "        return torch.cat(V, dim=1)  # Return all predicted concepts (last is COVID prob)\n",
    "\n",
    "# Instantiate model, optimizer with try-except for CUDA issues\n",
    "try:\n",
    "    model = C2BMModel().to(device)\n",
    "except RuntimeError as e:\n",
    "    print(f\"CUDA Error: {e}. Falling back to CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = C2BMModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training epoch with mixed loss\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    bce = nn.BCELoss()\n",
    "    mse = nn.MSELoss()\n",
    "    binary_indices = [1, 4]  # Gender, COVID\n",
    "    cont_indices = [0, 2, 3]  # Age, Country, Institution\n",
    "    for images, concepts, _ in loader:\n",
    "        images, concepts = images.to(device), concepts.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = 0\n",
    "        for i in binary_indices:\n",
    "            loss += bce(outputs[:, i], concepts[:, i])\n",
    "        for i in cont_indices:\n",
    "            loss += mse(outputs[:, i], concepts[:, i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# Evaluation (with optional intervention for fairness) with mixed loss\n",
    "def evaluate(model, loader, device, intervention=None):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    running_loss = 0.0\n",
    "    bce = nn.BCELoss()\n",
    "    mse = nn.MSELoss()\n",
    "    binary_indices = [1, 4]  # Gender, COVID\n",
    "    cont_indices = [0, 2, 3]  # Age, Country, Institution\n",
    "    with torch.no_grad():\n",
    "        for images, concepts, _ in loader:\n",
    "            images, concepts = images.to(device), concepts.to(device)\n",
    "            outputs = model(images, intervention=intervention)\n",
    "            loss = 0\n",
    "            for i in binary_indices:\n",
    "                loss += bce(outputs[:, i], concepts[:, i])\n",
    "            for i in cont_indices:\n",
    "                loss += mse(outputs[:, i], concepts[:, i])\n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs[:, -1] > 0.5).float().cpu().numpy()  # COVID pred\n",
    "            preds.extend(predicted)\n",
    "            true_labels.extend(concepts[:, -1].cpu().numpy())\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    prec = precision_score(true_labels, preds)\n",
    "    rec = recall_score(true_labels, preds)\n",
    "    f1 = f1_score(true_labels, preds)\n",
    "    return acc, prec, rec, f1, running_loss / len(loader)\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 50  # Increased from 5 to allow more training with early stopping\n",
    "early_stopping_patience = 9\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "best_model_path = \"/home/hailemicaelyimer/fairness/resnettt50/c2bm_model_best.pth\"\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_acc, val_prec, val_rec, val_f1, val_loss = evaluate(model, val_loader, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, Recall: {val_rec:.4f}, F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model with Val F1: {best_val_f1:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'c2bm_loss_plot.png'))\n",
    "plt.close()\n",
    "print(f\"Loss plot saved to {os.path.join(output_dir, 'c2bm_loss_plot.png')}\")\n",
    "\n",
    "# Load best model and evaluate on test set (with example intervention for fairness)\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "intervention = {3: 0}  # Set Institution to 0.5 to block Country effect\n",
    "test_acc, test_prec, test_rec, test_f1, test_loss = evaluate(model, test_loader, device, intervention=intervention)\n",
    "print(f\"\\nTest Results (with fairness intervention on Institution):\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, Precision: {test_prec:.4f}, Recall: {test_rec:.4f}, F1: {test_f1:.4f}\")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), \"/home/hailemicaelyimer/fairness/faurness/c2bm_model_final.pth\")\n",
    "print(\"C2BM model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the causal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results (with fairness intervention on Institution):\n",
      "Test Loss: 0.5989, Accuracy: 0.9836, Precision: 0.9803, Recall: 0.9837, F1: 0.9820\n",
      "Test Accuracy (no intervention): 0.9841\n",
      "\n",
      "Group Fairness for Age_normalized_binned (with intervention):\n",
      "Demographic Parity Difference: 0.057246 (No intervention: 0.060976)\n",
      "Disparate Impact: 0.877876 (No intervention: 0.869725)\n",
      "Equalized Odds Difference: 0.013853\n",
      "False Discovery Rate Difference: 0.004612\n",
      "Chi-squared p-value: 0.037706\n",
      "\n",
      "Per-Subgroup Metrics for Age_normalized_binned (with intervention):\n",
      "  Value Middle-aged:\n",
      "    Size: 452\n",
      "    Positive Rate: 0.411504\n",
      "    TPR: 0.994565\n",
      "    FPR: 0.011194\n",
      "    FDR: 0.016129\n",
      "  Value Young:\n",
      "    Size: 1440\n",
      "    Positive Rate: 0.468750\n",
      "    TPR: 0.980712\n",
      "    FPR: 0.018277\n",
      "    FDR: 0.020741\n",
      "\n",
      "Group Fairness for Gender_encoded (with intervention):\n",
      "Demographic Parity Difference: 0.018478 (No intervention: 0.016484)\n",
      "Disparate Impact: 0.960404 (No intervention: 0.964462)\n",
      "Equalized Odds Difference: 0.019773\n",
      "False Discovery Rate Difference: 0.022156\n",
      "Chi-squared p-value: 0.463782\n",
      "\n",
      "Per-Subgroup Metrics for Gender_encoded (with intervention):\n",
      "  Value 0.0:\n",
      "    Size: 705\n",
      "    Positive Rate: 0.466667\n",
      "    TPR: 0.978462\n",
      "    FPR: 0.028947\n",
      "    FDR: 0.033435\n",
      "  Value 1.0:\n",
      "    Size: 1187\n",
      "    Positive Rate: 0.448189\n",
      "    TPR: 0.986867\n",
      "    FPR: 0.009174\n",
      "    FDR: 0.011278\n",
      "\n",
      "Group Fairness for Country_encoded_binned (with intervention):\n",
      "Demographic Parity Difference: 0.581234 (No intervention: 0.580358)\n",
      "Disparate Impact: 0.198186 (No intervention: 0.197172)\n",
      "Equalized Odds Difference: 0.078499\n",
      "False Discovery Rate Difference: 0.022750\n",
      "Chi-squared p-value: 0.000000\n",
      "\n",
      "Per-Subgroup Metrics for Country_encoded_binned (with intervention):\n",
      "  Value Group 0:\n",
      "    Size: 996\n",
      "    Positive Rate: 0.724900\n",
      "    TPR: 0.995792\n",
      "    FPR: 0.042403\n",
      "    FDR: 0.016620\n",
      "  Value Group 1:\n",
      "    Size: 884\n",
      "    Positive Rate: 0.143665\n",
      "    TPR: 0.917293\n",
      "    FPR: 0.006658\n",
      "    FDR: 0.039370\n",
      "\n",
      "Group Fairness for Institution_encoded_binned (with intervention):\n",
      "Demographic Parity Difference: 0.091451 (No intervention: 0.085916)\n",
      "Disparate Impact: 0.827732 (No intervention: 0.836255)\n",
      "Equalized Odds Difference: 0.067879\n",
      "False Discovery Rate Difference: 0.062511\n",
      "Chi-squared p-value: 0.003198\n",
      "\n",
      "Per-Subgroup Metrics for Institution_encoded_binned (with intervention):\n",
      "  Value Group 0:\n",
      "    Size: 1568\n",
      "    Positive Rate: 0.439413\n",
      "    TPR: 0.981349\n",
      "    FPR: 0.005741\n",
      "    FDR: 0.007257\n",
      "  Value Group 1:\n",
      "    Size: 324\n",
      "    Positive Rate: 0.530864\n",
      "    TPR: 0.993789\n",
      "    FPR: 0.073620\n",
      "    FDR: 0.069767\n",
      "\n",
      "Enhanced fairness metrics saved to /home/hailemicaelyimer/fairness/resnettt50/c2bm_fairness_metrics_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Modified Evaluation Function to collect per-sample data\n",
    "def evaluate(model, loader, device, intervention=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    all_concepts = []\n",
    "    running_loss = 0.0\n",
    "    bce = nn.BCELoss()\n",
    "    mse = nn.MSELoss()\n",
    "    binary_indices = [1, 4]  # Gender, COVID\n",
    "    cont_indices = [0, 2, 3]  # Age, Country, Institution\n",
    "    with torch.no_grad():\n",
    "        for images, concepts, _ in loader:\n",
    "            images, concepts = images.to(device), concepts.to(device)\n",
    "            outputs = model(images, intervention=intervention)\n",
    "            loss = 0\n",
    "            for i in binary_indices:\n",
    "                loss += bce(outputs[:, i], concepts[:, i])\n",
    "            for i in cont_indices:\n",
    "                loss += mse(outputs[:, i], concepts[:, i])\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs[:, -1] > 0.5).float().cpu().numpy()\n",
    "            true_labels = concepts[:, -1].cpu().numpy()\n",
    "            concepts_np = concepts.cpu().numpy()\n",
    "            all_preds.extend(predicted)\n",
    "            all_true.extend(true_labels)\n",
    "            all_concepts.extend(concepts_np)\n",
    "    \n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    prec = precision_score(all_true, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_true, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_true, all_preds, zero_division=0)\n",
    "    \n",
    "    results_df = pd.DataFrame(all_concepts, columns=concept_cols)\n",
    "    results_df['y_pred'] = all_preds\n",
    "    results_df['y_true'] = all_true\n",
    "    \n",
    "    return acc, prec, rec, f1, running_loss / len(loader), results_df\n",
    "\n",
    "# Function to compute metrics for a subgroup\n",
    "def compute_metrics(group_df):\n",
    "    y_true = group_df['y_true']\n",
    "    y_pred = group_df['y_pred']\n",
    "    if len(y_true) < 10 or len(set(y_true)) < 2:  # Require min 10 samples\n",
    "        return None\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    pr = y_pred.mean()\n",
    "    tpr = rec\n",
    "    fpr = ((y_pred == 1) & (y_true == 0)).sum() / (y_true == 0).sum() if (y_true == 0).sum() > 0 else 0\n",
    "    fdr = 1 - prec if prec > 0 else 0\n",
    "    return {\n",
    "        'Size': len(group_df),\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': tpr,\n",
    "        'F1': f1,\n",
    "        'Positive Rate': pr,\n",
    "        'TPR': tpr,\n",
    "        'FPR': fpr,\n",
    "        'FDR': fdr\n",
    "    }\n",
    "\n",
    "# Evaluate with and without intervention\n",
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "intervention = {3: 0}\n",
    "test_acc, test_prec, test_rec, test_f1, test_loss, test_df_int = evaluate(model, test_loader, device, intervention=intervention)\n",
    "test_acc_no_int, _, _, _, _, test_df_no_int = evaluate(model, test_loader, device, intervention=None)\n",
    "\n",
    "# Bin continuous attributes directly on test_df_int and test_df_no_int\n",
    "for df in [test_df_int, test_df_no_int]:\n",
    "    for attr in ['Age_normalized', 'Country_encoded', 'Institution_encoded']:\n",
    "        try:\n",
    "            if len(df[attr].unique()) > 4:  # Bin only if enough unique values\n",
    "                df[f'{attr}_binned'] = pd.qcut(df[attr], q=4, duplicates='drop', labels=False)\n",
    "                # Map to meaningful labels\n",
    "                if attr == 'Age_normalized':\n",
    "                    df[f'{attr}_binned'] = df[f'{attr}_binned'].map({\n",
    "                        0: 'Young', 1: 'Middle-aged', 2: 'Older', 3: 'Elderly'\n",
    "                    })\n",
    "                else:\n",
    "                    df[f'{attr}_binned'] = df[f'{attr}_binned'].map({\n",
    "                        0: 'Group 0', 1: 'Group 1', 2: 'Group 2', 3: 'Group 3'\n",
    "                    })\n",
    "            else:\n",
    "                df[f'{attr}_binned'] = df[attr]  # Use original values if too few\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not bin {attr}: {e}. Using original values.\")\n",
    "            df[f'{attr}_binned'] = df[attr]\n",
    "\n",
    "print(f\"\\nTest Results (with fairness intervention on Institution):\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, Precision: {test_prec:.4f}, Recall: {test_rec:.4f}, F1: {test_f1:.4f}\")\n",
    "print(f\"Test Accuracy (no intervention): {test_acc_no_int:.4f}\")\n",
    "\n",
    "# Group fairness analysis\n",
    "group_attrs = ['Age_normalized_binned', 'Gender_encoded', 'Country_encoded_binned', 'Institution_encoded_binned']\n",
    "fairness_results = []\n",
    "\n",
    "for attr in group_attrs:\n",
    "    unique_vals = sorted(test_df_int[attr].unique(), key=lambda x: str(x))\n",
    "    subgroup_metrics_int = {}\n",
    "    subgroup_metrics_no_int = {}\n",
    "    pr_list_int = []\n",
    "    tpr_list_int = []\n",
    "    fpr_list_int = []\n",
    "    fdr_list_int = []\n",
    "    pr_list_no_int = []\n",
    "    valid_vals = []\n",
    "    \n",
    "    for val in unique_vals:\n",
    "        group_int = test_df_int[test_df_int[attr] == val]\n",
    "        group_no_int = test_df_no_int[test_df_no_int[attr] == val]\n",
    "        metrics_int = compute_metrics(group_int)\n",
    "        metrics_no_int = compute_metrics(group_no_int)\n",
    "        if metrics_int:\n",
    "            subgroup_metrics_int[val] = metrics_int\n",
    "            pr_list_int.append(metrics_int['Positive Rate'])\n",
    "            tpr_list_int.append(metrics_int['TPR'])\n",
    "            fpr_list_int.append(metrics_int['FPR'])\n",
    "            fdr_list_int.append(metrics_int['FDR'])\n",
    "            subgroup_metrics_no_int[val] = metrics_no_int or {}\n",
    "            pr_list_no_int.append(metrics_no_int['Positive Rate'] if metrics_no_int else 0)\n",
    "            valid_vals.append(val)\n",
    "    \n",
    "    if len(pr_list_int) < 2:\n",
    "        print(f\"\\nSkipping {attr}: Not enough subgroups for disparity calculation.\")\n",
    "        continue\n",
    "    \n",
    "    # Fairness metrics\n",
    "    dpd_int = max(pr_list_int) - min(pr_list_int)\n",
    "    di_int = min(pr_list_int) / max(pr_list_int) if max(pr_list_int) > 0 else 0.0\n",
    "    tpr_diff_int = max(tpr_list_int) - min(tpr_list_int)\n",
    "    fpr_diff_int = max(fpr_list_int) - min(fpr_list_int)\n",
    "    eod_int = max(tpr_diff_int, fpr_diff_int)\n",
    "    fdrd_int = max(fdr_list_int) - min(fdr_list_int)\n",
    "    \n",
    "    dpd_no_int = max(pr_list_no_int) - min(pr_list_no_int) if pr_list_no_int else 0.0\n",
    "    di_no_int = min(pr_list_no_int) / max(pr_list_no_int) if max(pr_list_no_int) > 0 else 0.0\n",
    "    \n",
    "    # Chi-squared test\n",
    "    contingency = pd.crosstab(test_df_int[attr], test_df_int['y_pred'])\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency) if contingency.shape[1] > 1 else (0, 1.0)\n",
    "    \n",
    "    print(f\"\\nGroup Fairness for {attr} (with intervention):\")\n",
    "    print(f\"Demographic Parity Difference: {dpd_int:.6f} (No intervention: {dpd_no_int:.6f})\")\n",
    "    print(f\"Disparate Impact: {di_int:.6f} (No intervention: {di_no_int:.6f})\")\n",
    "    print(f\"Equalized Odds Difference: {eod_int:.6f}\")\n",
    "    print(f\"False Discovery Rate Difference: {fdrd_int:.6f}\")\n",
    "    print(f\"Chi-squared p-value: {p_value:.6f}\")\n",
    "    \n",
    "    print(f\"\\nPer-Subgroup Metrics for {attr} (with intervention):\")\n",
    "    for val in valid_vals:\n",
    "        metrics = subgroup_metrics_int[val]\n",
    "        print(f\"  Value {val}:\")\n",
    "        print(f\"    Size: {metrics['Size']}\")\n",
    "        print(f\"    Positive Rate: {metrics['Positive Rate']:.6f}\")\n",
    "        print(f\"    TPR: {metrics['TPR']:.6f}\")\n",
    "        print(f\"    FPR: {metrics['FPR']:.6f}\")\n",
    "        print(f\"    FDR: {metrics['FDR']:.6f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=attr, y='y_pred', hue=test_df_int['y_pred'].map({0: 'Negative', 1: 'Positive'}), data=test_df_int)\n",
    "    plt.title(f'Positive Rate by {attr}')\n",
    "    plt.savefig(os.path.join(output_dir, f'positive_rate_by_{attr}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    fairness_results.append({\n",
    "        'Group': attr,\n",
    "        'Demographic Parity Difference (Int)': dpd_int,\n",
    "        'Disparate Impact (Int)': di_int,\n",
    "        'Equalized Odds Difference (Int)': eod_int,\n",
    "        'False Discovery Rate Difference (Int)': fdrd_int,\n",
    "        'DPD (No Int)': dpd_no_int,\n",
    "        'DI (No Int)': di_no_int,\n",
    "        'Chi-squared p-value': p_value,\n",
    "        **{f'Positive Rate ({val}, Int)': subgroup_metrics_int[val]['Positive Rate'] for val in valid_vals},\n",
    "        **{f'TPR ({val}, Int)': subgroup_metrics_int[val]['TPR'] for val in valid_vals},\n",
    "        **{f'FPR ({val}, Int)': subgroup_metrics_int[val]['FPR'] for val in valid_vals},\n",
    "        **{f'FDR ({val}, Int)': subgroup_metrics_int[val]['FDR'] for val in valid_vals}\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "fairness_df = pd.DataFrame(fairness_results)\n",
    "fairness_df.to_csv(os.path.join(output_dir, '/home/hailemicaelyimer/fairness/resnettt50/c2bm_fairness_metrics_enhanced.csv'), index=False)\n",
    "print(f\"\\nEnhanced fairness metrics saved to {os.path.join(output_dir, 'c2bm_fairness_metrics_enhanced.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immigration_assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
